{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split , Dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Suppressing warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download -d cashbowman/ai-generated-images-vs-real-images\n",
    "\n",
    "path = 'ai-generated-images-vs-real-images'\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile('ai-generated-images-vs-real-images.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageFolder object\n",
    "data = datasets.ImageFolder(root=path)\n",
    "\n",
    "# Extract labels from the dataset\n",
    "images, labels = zip(*data.samples)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, stratify=labels)\n",
    "\n",
    "# Split train set into train and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels)\n",
    "\n",
    "# Zip train images with train labels and create DataFrame\n",
    "train_data_df = pd.DataFrame({'images': train_images, 'labels': train_labels})\n",
    "\n",
    "# Zip test images with test labels and create DataFrame\n",
    "test_data_df = pd.DataFrame({'images': test_images, 'labels': test_labels})\n",
    "\n",
    "# Zip train images with train labels and create DataFrame\n",
    "val_data_df = pd.DataFrame({'images': val_images, 'labels': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        # Convert image to tensor\n",
    "        image = self.transform(image)\n",
    "\n",
    "        # Ensure image has three channels (RGB)\n",
    "        if image.shape[0] == 1:  # If grayscale, convert to RGB\n",
    "            image = image.expand(3, -1, -1)  # Expand grayscale to three channels\n",
    "        elif image.shape[0] == 4:  # If RGBA, remove alpha channel\n",
    "            image = image[:3]  # Remove alpha channel\n",
    "\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "img_size = 224  # Adjust as per your requirement\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(size=img_size, scale=(0.8, 1.0)),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    #transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Assuming RGB images\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Assuming RGB images\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Assuming RGB images\n",
    "])\n",
    "\n",
    "# Create custom datasets for train and test sets\n",
    "train_dataset = CustomImageDataset(train_data_df, transform=train_transform)\n",
    "test_dataset = CustomImageDataset(test_data_df, transform=test_transform)\n",
    "val_dataset = CustomImageDataset(val_data_df, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 20\n",
      "Number of batches in test_loader: 7\n",
      "Number of batches in val_loader: 5\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of batches in train_loader:\", len(train_loader))\n",
    "print(\"Number of batches in test_loader:\", len(test_loader))\n",
    "print(\"Number of batches in val_loader:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\louis/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights = 'DEFAULT')\n",
    "# Freeze pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier to output binary classification\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1(weights = 'DEFAULT')\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape        Output Shape       Param #            Trainable\n",
       "================================================================================================================\n",
       "ResNet (ResNet)                          [1, 3, 112, 112]   [1, 1]             --                 Partial\n",
       "├─Conv2d (conv1)                         [1, 3, 112, 112]   [1, 64, 56, 56]    (9,408)            False\n",
       "├─BatchNorm2d (bn1)                      [1, 64, 56, 56]    [1, 64, 56, 56]    (128)              False\n",
       "├─ReLU (relu)                            [1, 64, 56, 56]    [1, 64, 56, 56]    --                 --\n",
       "├─MaxPool2d (maxpool)                    [1, 64, 56, 56]    [1, 64, 28, 28]    --                 --\n",
       "├─Sequential (layer1)                    [1, 64, 28, 28]    [1, 64, 28, 28]    --                 False\n",
       "│    └─BasicBlock (0)                    [1, 64, 28, 28]    [1, 64, 28, 28]    --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 64, 28, 28]    [1, 64, 28, 28]    (36,864)           False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 28, 28]    [1, 64, 28, 28]    (128)              False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 28, 28]    [1, 64, 28, 28]    --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 28, 28]    [1, 64, 28, 28]    (36,864)           False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 28, 28]    [1, 64, 28, 28]    (128)              False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 28, 28]    [1, 64, 28, 28]    --                 --\n",
       "│    └─BasicBlock (1)                    [1, 64, 28, 28]    [1, 64, 28, 28]    --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 64, 28, 28]    [1, 64, 28, 28]    (36,864)           False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 64, 28, 28]    [1, 64, 28, 28]    (128)              False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 28, 28]    [1, 64, 28, 28]    --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 64, 28, 28]    [1, 64, 28, 28]    (36,864)           False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 64, 28, 28]    [1, 64, 28, 28]    (128)              False\n",
       "│    │    └─ReLU (relu)                  [1, 64, 28, 28]    [1, 64, 28, 28]    --                 --\n",
       "├─Sequential (layer2)                    [1, 64, 28, 28]    [1, 128, 14, 14]   --                 False\n",
       "│    └─BasicBlock (0)                    [1, 64, 28, 28]    [1, 128, 14, 14]   --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 64, 28, 28]    [1, 128, 14, 14]   (73,728)           False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 14, 14]   [1, 128, 14, 14]   (256)              False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 14, 14]   [1, 128, 14, 14]   --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 14, 14]   [1, 128, 14, 14]   (147,456)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 14, 14]   [1, 128, 14, 14]   (256)              False\n",
       "│    │    └─Sequential (downsample)      [1, 64, 28, 28]    [1, 128, 14, 14]   (8,448)            False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 14, 14]   [1, 128, 14, 14]   --                 --\n",
       "│    └─BasicBlock (1)                    [1, 128, 14, 14]   [1, 128, 14, 14]   --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 128, 14, 14]   [1, 128, 14, 14]   (147,456)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 128, 14, 14]   [1, 128, 14, 14]   (256)              False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 14, 14]   [1, 128, 14, 14]   --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 128, 14, 14]   [1, 128, 14, 14]   (147,456)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 128, 14, 14]   [1, 128, 14, 14]   (256)              False\n",
       "│    │    └─ReLU (relu)                  [1, 128, 14, 14]   [1, 128, 14, 14]   --                 --\n",
       "├─Sequential (layer3)                    [1, 128, 14, 14]   [1, 256, 7, 7]     --                 False\n",
       "│    └─BasicBlock (0)                    [1, 128, 14, 14]   [1, 256, 7, 7]     --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 128, 14, 14]   [1, 256, 7, 7]     (294,912)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 7, 7]     [1, 256, 7, 7]     (512)              False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 7, 7]     [1, 256, 7, 7]     --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 7, 7]     [1, 256, 7, 7]     (589,824)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 7, 7]     [1, 256, 7, 7]     (512)              False\n",
       "│    │    └─Sequential (downsample)      [1, 128, 14, 14]   [1, 256, 7, 7]     (33,280)           False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 7, 7]     [1, 256, 7, 7]     --                 --\n",
       "│    └─BasicBlock (1)                    [1, 256, 7, 7]     [1, 256, 7, 7]     --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 7, 7]     [1, 256, 7, 7]     (589,824)          False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 256, 7, 7]     [1, 256, 7, 7]     (512)              False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 7, 7]     [1, 256, 7, 7]     --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 256, 7, 7]     [1, 256, 7, 7]     (589,824)          False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 256, 7, 7]     [1, 256, 7, 7]     (512)              False\n",
       "│    │    └─ReLU (relu)                  [1, 256, 7, 7]     [1, 256, 7, 7]     --                 --\n",
       "├─Sequential (layer4)                    [1, 256, 7, 7]     [1, 512, 4, 4]     --                 False\n",
       "│    └─BasicBlock (0)                    [1, 256, 7, 7]     [1, 512, 4, 4]     --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 256, 7, 7]     [1, 512, 4, 4]     (1,179,648)        False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 4, 4]     [1, 512, 4, 4]     (1,024)            False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 4, 4]     [1, 512, 4, 4]     --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 4, 4]     [1, 512, 4, 4]     (2,359,296)        False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 4, 4]     [1, 512, 4, 4]     (1,024)            False\n",
       "│    │    └─Sequential (downsample)      [1, 256, 7, 7]     [1, 512, 4, 4]     (132,096)          False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 4, 4]     [1, 512, 4, 4]     --                 --\n",
       "│    └─BasicBlock (1)                    [1, 512, 4, 4]     [1, 512, 4, 4]     --                 False\n",
       "│    │    └─Conv2d (conv1)               [1, 512, 4, 4]     [1, 512, 4, 4]     (2,359,296)        False\n",
       "│    │    └─BatchNorm2d (bn1)            [1, 512, 4, 4]     [1, 512, 4, 4]     (1,024)            False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 4, 4]     [1, 512, 4, 4]     --                 --\n",
       "│    │    └─Conv2d (conv2)               [1, 512, 4, 4]     [1, 512, 4, 4]     (2,359,296)        False\n",
       "│    │    └─BatchNorm2d (bn2)            [1, 512, 4, 4]     [1, 512, 4, 4]     (1,024)            False\n",
       "│    │    └─ReLU (relu)                  [1, 512, 4, 4]     [1, 512, 4, 4]     --                 --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 4, 4]     [1, 512, 1, 1]     --                 --\n",
       "├─Linear (fc)                            [1, 512]           [1, 1]             513                True\n",
       "================================================================================================================\n",
       "Total params: 11,177,025\n",
       "Trainable params: 513\n",
       "Non-trainable params: 11,176,512\n",
       "Total mult-adds (Units.MEGABYTES): 484.86\n",
       "================================================================================================================\n",
       "Input size (MB): 0.15\n",
       "Forward/backward pass size (MB): 10.09\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 54.95\n",
       "================================================================================================================"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size = [1,3,112,112],\n",
    "        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width = 18,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.best_accuracy = None  # New attribute to track best accuracy\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss, val_accuracy):\n",
    "        if self.best_loss is None or val_loss < self.best_loss:  # Update if val_loss is better\n",
    "            self.best_loss = val_loss\n",
    "            self.best_accuracy = val_accuracy  # Update best accuracy along with best loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}. \" \\\n",
    "                          # f\"Best Loss: {self.best_loss:.4f}, Best Accuracy: {self.best_accuracy:.2f}%\"\n",
    "\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}. \" \\\n",
    "                          # f\"Best Loss: {self.best_loss:.4f}, Best Accuracy: {self.best_accuracy:.2f}%\"\n",
    "\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs. \" \\\n",
    "                          # f\"Best Loss: {self.best_loss:.4f}, Best Accuracy: {self.best_accuracy:.2f}%\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs. \" \\\n",
    "                              f\"Best Loss: {self.best_loss:.4f}, Best Accuracy: {self.best_accuracy:.2f}%\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 10, min_delta = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 10, min_delta = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def train_step(model:torch.nn.Module,\n",
    "               dataloader:torch.utils.data.DataLoader,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.\n",
    "    accuracy_train = BinaryAccuracy(threshold = 0.5).to(device)\n",
    "\n",
    "    for batch,(X,y) in enumerate(tqdm(dataloader)):\n",
    "        X,y = X.to(device,dtype=torch.float32), y.to(device,dtype=torch.float32)\n",
    "\n",
    "        y_pred = model(X).squeeze()\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.detach().cpu().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_proba = torch.sigmoid(y_pred)\n",
    "        accuracy_train.update(y_proba, y)\n",
    "\n",
    "    train_accuracy = accuracy_train.compute()\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def val_step(model:torch.nn.Module,\n",
    "              dataloader:torch.utils.data.DataLoader,\n",
    "              loss_fn:torch.nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.\n",
    "    accuracy_test = BinaryAccuracy(threshold = 0.5).to(device)\n",
    "\n",
    "    for batch,(X,y) in enumerate(tqdm(dataloader)):\n",
    "        X,y = X.to(device,dtype=torch.float32), y.to(device,dtype=torch.float32)\n",
    "\n",
    "        y_pred = model(X).squeeze()\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        test_loss += loss.detach().cpu().item()\n",
    "\n",
    "        y_proba = torch.sigmoid(y_pred)\n",
    "        accuracy_test.update(y_proba, y)\n",
    "\n",
    "    test_accuracy = accuracy_test.compute()\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:torch.nn.Module,\n",
    "          train_dataloader:torch.utils.data.DataLoader,\n",
    "          val_dataloader:torch.utils.data.DataLoader,\n",
    "          test_dataloader:torch.utils.data.DataLoader,\n",
    "          loss_fn:torch.nn.Module,\n",
    "          optimzier:torch.optim.Optimizer,\n",
    "          epochs:int):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    results = {'train_loss':[],\n",
    "               'train_accuracy':[],\n",
    "               'val_loss':[],\n",
    "               'val_accuracy':[]}\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_accuracy = train_step(model = model,\n",
    "                                                dataloader = train_dataloader,\n",
    "                                                loss_fn = loss_fn,\n",
    "                                                optimizer = optimizer)\n",
    "\n",
    "        val_loss, val_accuracy = val_step(model = model,\n",
    "                                             dataloader = val_dataloader,\n",
    "                                             loss_fn = loss_fn)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Epoch: {epoch+1} | \",\n",
    "              f\"Train Loss: {train_loss:.4f} | \",\n",
    "              f\"Train Accuracy: {train_accuracy:.4f} | \",\n",
    "              f\"Validation Loss: {val_loss:.4f} | \",\n",
    "              f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        print(early_stopping.status)\n",
    "        if early_stopping(model,val_loss,val_accuracy):\n",
    "            print(early_stopping.status)\n",
    "            print(\"Early Stopping!!\")\n",
    "            test_loss, test_accuracy = val_step(model = model,\n",
    "                                      dataloader = test_dataloader,\n",
    "                                      loss_fn = loss_fn)\n",
    "            print(f\"Test Loss: {test_loss:.4f} | \",\n",
    "              f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "            break\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_accuracy\"].append(train_accuracy.detach().cpu().item())\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_accuracy\"].append(val_accuracy.detach().cpu().item())\n",
    "\n",
    "    test_loss, test_accuracy = val_step(model = model,\n",
    "                          dataloader = test_dataloader,\n",
    "                          loss_fn = loss_fn)\n",
    "    print(f\"Test Loss: {test_loss:.4f} | \",\n",
    "      f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:02<00:50,  2.66s/it]\n",
      " 10%|█         | 2/20 [00:05<00:49,  2.78s/it]\n",
      " 15%|█▌        | 3/20 [00:08<00:50,  2.96s/it]\n",
      " 20%|██        | 4/20 [00:12<00:54,  3.40s/it]\n",
      " 25%|██▌       | 5/20 [00:15<00:46,  3.13s/it]\n",
      " 30%|███       | 6/20 [00:18<00:41,  2.94s/it]\n",
      " 35%|███▌      | 7/20 [00:20<00:37,  2.88s/it]\n",
      " 40%|████      | 8/20 [00:23<00:32,  2.71s/it]\n",
      " 45%|████▌     | 9/20 [00:25<00:28,  2.57s/it]\n",
      " 50%|█████     | 10/20 [00:27<00:25,  2.58s/it]\n",
      " 55%|█████▌    | 11/20 [00:30<00:24,  2.70s/it]\n",
      " 60%|██████    | 12/20 [00:33<00:21,  2.63s/it]\n",
      " 65%|██████▌   | 13/20 [00:36<00:18,  2.68s/it]\n",
      " 70%|███████   | 14/20 [00:39<00:17,  2.87s/it]\n",
      " 75%|███████▌  | 15/20 [00:42<00:14,  2.86s/it]\n",
      " 80%|████████  | 16/20 [00:45<00:12,  3.07s/it]\n",
      " 85%|████████▌ | 17/20 [00:48<00:08,  2.97s/it]\n",
      " 90%|█████████ | 18/20 [00:51<00:05,  2.87s/it]\n",
      " 95%|█████████▌| 19/20 [00:53<00:02,  2.76s/it]\n",
      "100%|██████████| 20/20 [00:54<00:00,  2.75s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      " 20%|██        | 1/5 [00:02<00:10,  2.53s/it]\n",
      " 40%|████      | 2/5 [00:05<00:07,  2.56s/it]\n",
      " 60%|██████    | 3/5 [00:07<00:05,  2.51s/it]\n",
      " 80%|████████  | 4/5 [00:09<00:02,  2.40s/it]\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 |  Train Loss: 0.6242 |  Train Accuracy: 0.6254 |  Validation Loss: 0.5848 |  Validation Accuracy: 0.6795\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:06<01:06, 66.77s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  5%|▌         | 1/20 [00:02<00:50,  2.66s/it]\n",
      " 10%|█         | 2/20 [00:05<00:45,  2.52s/it]\n",
      " 15%|█▌        | 3/20 [00:07<00:42,  2.51s/it]\n",
      " 20%|██        | 4/20 [00:10<00:40,  2.51s/it]\n",
      " 25%|██▌       | 5/20 [00:13<00:44,  2.97s/it]\n",
      " 30%|███       | 6/20 [00:17<00:42,  3.03s/it]\n",
      " 35%|███▌      | 7/20 [00:20<00:41,  3.21s/it]\n",
      " 40%|████      | 8/20 [00:24<00:41,  3.49s/it]\n",
      " 45%|████▌     | 9/20 [00:28<00:37,  3.45s/it]\n",
      " 50%|█████     | 10/20 [00:31<00:34,  3.45s/it]\n",
      " 55%|█████▌    | 11/20 [00:35<00:32,  3.56s/it]\n",
      " 60%|██████    | 12/20 [00:39<00:29,  3.64s/it]\n",
      " 65%|██████▌   | 13/20 [00:43<00:27,  3.94s/it]\n",
      " 70%|███████   | 14/20 [00:48<00:24,  4.07s/it]\n",
      " 75%|███████▌  | 15/20 [00:52<00:20,  4.19s/it]\n",
      " 80%|████████  | 16/20 [00:56<00:16,  4.01s/it]\n",
      " 85%|████████▌ | 17/20 [00:59<00:11,  3.84s/it]\n",
      " 90%|█████████ | 18/20 [01:02<00:07,  3.68s/it]\n",
      " 95%|█████████▌| 19/20 [01:06<00:03,  3.73s/it]\n",
      "100%|██████████| 20/20 [01:08<00:00,  3.44s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      " 20%|██        | 1/5 [00:03<00:13,  3.44s/it]\n",
      " 40%|████      | 2/5 [00:07<00:10,  3.64s/it]\n",
      " 60%|██████    | 3/5 [00:10<00:07,  3.50s/it]\n",
      " 80%|████████  | 4/5 [00:13<00:03,  3.42s/it]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 |  Train Loss: 0.6041 |  Train Accuracy: 0.6656 |  Validation Loss: 0.5773 |  Validation Accuracy: 0.6667\n",
      "Improvement found, counter reset to 0. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:32<00:00, 76.33s/it]\n",
      "100%|██████████| 7/7 [00:23<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5810 |  Test Accuracy: 0.6205\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "EPOCHS = 200\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "MODEL_RESULTS = train(model, train_loader, val_loader, test_loader, criterion, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting training and validation metrics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(MODEL_RESULTS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting training and validation metrics\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(MODEL_RESULTS[\"train_loss\"], label = 'Training Loss')\n",
    "plt.plot(MODEL_RESULTS[\"val_loss\"], label = 'Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(MODEL_RESULTS[\"train_accuracy\"], label = 'Training Accuracy')\n",
    "plt.plot(MODEL_RESULTS[\"val_accuracy\"], label = 'Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrix for validation data\n",
    "model.eval()\n",
    "allLabels = []\n",
    "allPreds = []\n",
    "\n",
    "testLoader = test_loader\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testLoader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predictions = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "        allLabels.extend(labels.cpu().numpy())\n",
    "        allPreds.extend(predictions.cpu().numpy())\n",
    "\n",
    "        # for i in range(len(inputs.cpu())):\n",
    "        #   image = inputs.cpu()[i]\n",
    "        #   label = labels.cpu().numpy()[i]\n",
    "        #   prediction = predictions.cpu().numpy()[i]\n",
    "        #   if label != prediction:\n",
    "        #     # Plotting the image\n",
    "        #     plt.imshow(image.permute(1, 2, 0))\n",
    "        #     plt.title(f\"Label: {label}, Prediction: {prediction}\")\n",
    "        #     plt.axis('off')\n",
    "        #     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "allLabels = np.array(allLabels)\n",
    "allPreds = np.array(allPreds)\n",
    "\n",
    "matrix = confusion_matrix(allLabels, allPreds)\n",
    "\n",
    "classes = ['aiart', 'realart']  # Define your classes manually\n",
    "sns.heatmap(matrix, annot = True, fmt = 'd', cmap = 'Blues', xticklabels = classes, yticklabels = classes, cbar = False)\n",
    "plt.title('Confusion Matrix - Validation Set', fontsize = 16)\n",
    "plt.xlabel('Predicted Label', fontsize = 14)\n",
    "plt.ylabel('True Label', fontsize = 14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
